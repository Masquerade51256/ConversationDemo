# jieba分词与tf-idf特征提取

#### 此demo主要展示jieba自带的基于 TF-IDF 算法的关键词抽取功能效果

### 环境配置

​	全自动安装：`easy_install jieba` 或者 `pip install jieba` / `pip3 install jieba`

​	半自动安装：先下载 <http://pypi.python.org/pypi/jieba/> ，解压后运行 `python setup.py install`

​	手动安装：将 jieba 目录放置于当前目录或者 site-packages 目录通过 `import jieba` 来引用

​	

​	p.s.测试过全自动安装的三种方法均可行，适配python版本2.7/3.x

### main.py

​	此文件可直接在编辑器中运行，字符串变量content为需要分析的内容

```
content = "中文分词是中文文本处理的一个基础步骤，也是中文人机自然语言交互的基础模块，在进行中文自然语言处理时，通常需要先进行分词。"
```

​	下为运行分析结果，以`(词，tfidf权值)`的形式展示

```
中文,1.552020002504762

分词,1.1146145785333335

自然语言,0.9938039761142857

文本处理,0.585297130452381

人机,0.49129327207142853

基础,0.45364101004952384

交互,0.42942265378047617

模块,0.42662072520809524

步骤,0.38339775581095237

进行,0.354964266192381

通常,0.2597405194757143

处理,0.25765979320761906

需要,0.20688003064285715

一个,0.1341690939109524
```



### extract_tags.py

​	通过命令行打开，将要识别的内容放在`content`文件中，通过terminal命令进行分析

```
python extract_tags.py content -k 20
//此处20为topk值，表示返回几个结果
//content文件中内容为与上述content变量相同
```

​	结果如下

```
中文,1.552020002504762
分词,1.1146145785333335
自然语言,0.9938039761142857
文本处理,0.585297130452381
人机,0.49129327207142853
基础,0.45364101004952384
交互,0.42942265378047617
模块,0.42662072520809524
步骤,0.38339775581095237
进行,0.354964266192381
通常,0.2597405194757143
处理,0.25765979320761906
需要,0.20688003064285715
一个,0.1341690939109524
```

